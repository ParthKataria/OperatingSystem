{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Assignment_IIT2019016.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhMN9Q7lDFnZ",
        "outputId": "0acfc825-d104-48e5-df81-7148a30850a6"
      },
      "source": [
        "#Question-6(c)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "input_data = pd.read_csv('https://raw.githubusercontent.com/ParthKataria/OperatingSystem/master/Housing%20Price%20data%20set.csv')\n",
        "\n",
        "Price = input_data['price']\n",
        "FloorArea = input_data['lotsize']\n",
        "NoOfBedrooms = input_data['bedrooms']\n",
        "NoOfBathrooms = input_data['bathrms']\n",
        "\n",
        "# Performing feature scanning on FloorArea\n",
        "FloorArea_Mean = np.mean(FloorArea)\n",
        "FloorArea_Max = max(FloorArea)\n",
        "FloorArea_Min = min(FloorArea)\n",
        "FloorArea_Scaled = []\n",
        "for i in FloorArea:\n",
        "\tFloorArea_Scaled.append((i - FloorArea_Mean) / (FloorArea_Max - FloorArea_Min))\n",
        "\n",
        "#segmenting the features\n",
        "FeaturesTrain = []\n",
        "for i in range(383):\n",
        "\tFeaturesTrain.append([1, FloorArea_Scaled[i], NoOfBedrooms[i], NoOfBathrooms[i]])\n",
        "PriceTrain = Price[:383]\n",
        "PriceTest = []\n",
        "FeaturesTest = []\n",
        "for i in range(383, len(Price)):\n",
        "\tFeaturesTest.append([1, FloorArea_Scaled[i], NoOfBedrooms[i], NoOfBathrooms[i]])\n",
        "\tPriceTest.append(Price[i])\n",
        "m = len(FeaturesTrain)\n",
        "\n",
        "# Function to calculate Slope to find coefficients\n",
        "def Slope(Coeff, FeaturesTrain, PriceTrain, ind):\n",
        "\tError = 0\n",
        "\tfor i in range(len(FeaturesTrain)):\n",
        "\t\titr = 0\n",
        "\t\tfor j in range(len(Coeff)):\n",
        "\t\t\titr = itr + Coeff[j] * FeaturesTrain[i][j]\n",
        "\t\tError += (itr - PriceTrain[i]) * FeaturesTrain[i][ind]\n",
        "\treturn Error\n",
        "\n",
        "# Using scaled batch gradient without regularisation\n",
        "print(\"Using scaled batch gradient without regularisation\")\n",
        "LearningRate = 0.001\n",
        "m = len(FeaturesTrain)\n",
        "\n",
        "Coeff = [0, 0, 0, 0]\n",
        "print(\"Initial coefficients: \")\n",
        "print(Coeff)\n",
        "for i in range(5000):\n",
        "\tTempCoeff = Coeff.copy()\n",
        "\tfor j in range(len(Coeff)):\n",
        "\t\tTempCoeff[j] = TempCoeff[j] - ((LearningRate / m) * (Slope(Coeff, FeaturesTrain, PriceTrain, j)))\n",
        "\tCoeff = TempCoeff.copy()\n",
        "print(\"Final coefficients are:\")\n",
        "print(Coeff)\n",
        "\n",
        "# Finding Mean absolute percentage error.\n",
        "Error = 0\n",
        "for i in range(len(FeaturesTest)):\n",
        "\tpredicted = 0\n",
        "\tfor j in range(len(Coeff)):\n",
        "\t  \tpredicted = predicted + Coeff[j] * FeaturesTest[i][j]\n",
        "\tError += abs(predicted - PriceTest[i]) / PriceTest[i]\n",
        "Error = (Error / len(FeaturesTest)) * 90\n",
        "print(\"Mean absolute percentage error is : \" + str(Error))\n",
        "print()\n",
        "\n",
        "# Using scaled batch gradient with regularisation\n",
        "print(\"Using scaled batch gradient with regularisation\")\n",
        "LearningRate = 0.001\n",
        "LambdaParameter = -49\n",
        "Coeff = [0, 0, 0, 0]\n",
        "print(\"Initial coefficients: \")\n",
        "print(Coeff)\n",
        "for epochs in range(5000):\n",
        "\tTempCoeff = Coeff.copy()\n",
        "\tfor j in range(len(Coeff)):\n",
        "\t\tif (j == 0):\n",
        "\t\t\tTempCoeff[j] = TempCoeff[j] - ((LearningRate / m) * (Slope(Coeff, FeaturesTrain, PriceTrain, j)))\t\n",
        "\t\telse:\n",
        "\t\t\tTempCoeff[j] = (1 - LearningRate * LambdaParameter / m) * TempCoeff[j] - ((LearningRate / m) * (Slope(Coeff, FeaturesTrain, PriceTrain, j)))\n",
        "\tCoeff = TempCoeff.copy()\n",
        "print(\"Final coefficients are:\")\n",
        "print(Coeff)\n",
        "\n",
        "# Finding Mean absolute percentage error.\n",
        "Error = 0\n",
        "for i in range(len(FeaturesTest)):\n",
        "\tpredicted = 0\n",
        "\tfor j in range(len(Coeff)):\n",
        "\t  \tpredicted = predicted + Coeff[j] * FeaturesTest[i][j]\n",
        "\tError += abs(predicted - PriceTest[i]) / PriceTest[i]\n",
        "Error = (Error / len(FeaturesTest)) * 100\n",
        "print(\"Mean absolute percentage error is : \" + str(Error))\n",
        "print()\n",
        "\n",
        "def SlopeStoch(Coeff,FeaturesTrain,ActualVal,ind):\n",
        "\titr = 0\n",
        "\tfor j in range(len(Coeff)):\n",
        "\t\titr = itr + Coeff[j]*FeaturesTrain[j]\n",
        "\treturn (itr - ActualVal) * FeaturesTrain[ind]\n",
        "\n",
        "# Using Scaled Stochastic gradient without regularisation.\n",
        "print(\"Using Stochastic gradient without regularisation\")\n",
        "\n",
        "LearningRate = 0.005\n",
        "Coeff = [0, 0, 0, 0]\n",
        "print(\"Initial coefficients: \")\n",
        "print(Coeff)\n",
        "\n",
        "for iter in range(10):\n",
        "\tfor i in range(len(PriceTrain)):\n",
        "\t\tTempCoeff = Coeff.copy()\n",
        "\t\tfor j in range(4):\n",
        "\t\t\tTempCoeff[j] = TempCoeff[j] - (LearningRate * (SlopeStoch(Coeff, FeaturesTrain[i], PriceTrain[i], j)))\n",
        "\t\tCoeff = TempCoeff.copy()\n",
        "\n",
        "print(\"Final coefficients are:\")\n",
        "print(Coeff)\n",
        "\n",
        "# Finding Mean absolute percentage error.\n",
        "Error = 0\n",
        "for i in range(len(FeaturesTest)):\n",
        "\tpredicted = 0\n",
        "\tfor j in range(len(Coeff)):\n",
        "\t  \tpredicted = predicted + Coeff[j] * FeaturesTest[i][j]\n",
        "\tError += abs(predicted - PriceTest[i]) / PriceTest[i]\n",
        "Error = (Error / len(FeaturesTest)) * 100\n",
        "print(\"Mean absolute percentage error is : \" + str(Error))\n",
        "print()\n",
        "\n",
        "# Using Scaled Minibatch gradient without regularisation for batch size = 20\n",
        "print(\"Using Scaled Minibatch gradient without regularisation for batch size = 20\")\n",
        "\n",
        "BatchSize = 20;\n",
        "LearningRate = 0.002\n",
        "Coeff = [0, 0, 0, 0]\n",
        "NoOfBatches = math.ceil(len(PriceTrain) / BatchSize)\n",
        "equallyDiv = False\n",
        "if (len(PriceTrain) % BatchSize == 0):\n",
        "\tequallyDiv = True;\n",
        "\n",
        "for epoch in range(30):\n",
        "\tfor batch in range(NoOfBatches):\n",
        "\t\tSummation = [0, 0, 0, 0]\n",
        "\t\tfor j in range(len(Coeff)):\n",
        "\t\t\tfor i in range(BatchSize):\n",
        "\t\t\t\tif (batch * BatchSize + i == len(FeaturesTrain)):\n",
        "\t\t\t\t\tbreak\n",
        "\t\t\t\tPredictedValue = 0.0\n",
        "\t\t\t\tfor wj in range(len(Coeff)):\n",
        "\t\t\t\t\tPredictedValue += Coeff[wj] * FeaturesTrain[batch * BatchSize + i][wj]\n",
        "\t\t\t\tPredictedValue -= PriceTrain[batch * BatchSize + i]\n",
        "\t\t\t\tPredictedValue *= FeaturesTrain[batch * BatchSize + i][j]\n",
        "\t\t\t\tSummation[j] += PredictedValue;\n",
        "\n",
        "\t\tif (not equallyDiv and batch == NoOfBatches - 1):\n",
        "\t\t\tfor j in range(len(Summation)):\n",
        "\t\t\t\tCoeff[j] -= (Summation[j] / (len(PriceTrain) % BatchSize)) * LearningRate\n",
        "\t\telse:\n",
        "\t\t\tfor j in range(len(Summation)):\n",
        "\t\t\t\tCoeff[j] -= (Summation[j] / BatchSize) * LearningRate\n",
        "print(\"Final coefficients are:\")\n",
        "print(Coeff)\n",
        "\n",
        "# Finding Mean absolute percentage error.\n",
        "Error = 0\n",
        "for i in range(len(FeaturesTest)):\n",
        "\tpredicted = 0\n",
        "\tfor j in range(len(Coeff)):\n",
        "\t  \tpredicted = predicted + Coeff[j] * FeaturesTest[i][j]\n",
        "\tError += abs(predicted - PriceTest[i]) / PriceTest[i]\n",
        "Error = (Error / len(FeaturesTest)) * 100\n",
        "print(\"Mean absolute percentage error is : \" + str(Error))\n",
        "print()\n",
        "\n",
        "# Using Scaled Minibatch gradient with regularisation for batch size = 20\n",
        "print(\"Using Scaled Minibatch gradient with regularisation for batch size = 20\")\n",
        "\n",
        "BatchSize = 20;\n",
        "LearningRate = 0.002\n",
        "LambdaParameter = -372\n",
        "Coeff = [0, 0, 0, 0]\n",
        "NoOfBatches = math.ceil(len(PriceTrain) / BatchSize)\n",
        "equallyDiv = False\n",
        "if (len(PriceTrain) % BatchSize == 0):\n",
        "\tequallyDiv = True;\n",
        "\n",
        "for epoch in range(30):\n",
        "\tfor batch in range(NoOfBatches):\n",
        "\t\tSummation = [0, 0, 0, 0]\n",
        "\t\tfor j in range(len(Coeff)):\n",
        "\t\t\tfor i in range(BatchSize):\n",
        "\t\t\t\tif (batch * BatchSize + i == len(FeaturesTrain)):\n",
        "\t\t\t\t\tbreak\n",
        "\t\t\t\tPredictedValue = 0.0\n",
        "\t\t\t\tfor wj in range(len(Coeff)):\n",
        "\t\t\t\t\tPredictedValue += Coeff[wj] * FeaturesTrain[batch * BatchSize + i][wj]\n",
        "\t\t\t\tPredictedValue -= PriceTrain[batch * BatchSize + i]\n",
        "\t\t\t\tPredictedValue *= FeaturesTrain[batch * BatchSize + i][j]\n",
        "\t\t\t\tSummation[j] += PredictedValue;\n",
        "\n",
        "\t\tif (not equallyDiv and batch == NoOfBatches - 1):\n",
        "\t\t\tfor j in range(len(Summation)):\n",
        "\t\t\t\tif j == 0:\n",
        "\t\t\t\t\tCoeff[j] -= (Summation[j] / (len(PriceTrain) % BatchSize)) * LearningRate\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tCoeff[j] = (1 - LearningRate * LambdaParameter / m) * Coeff[j] - (Summation[j] / (len(PriceTrain) % BatchSize)) * LearningRate\n",
        "\t\telse:\n",
        "\t\t\tfor j in range(len(Summation)):\n",
        "\t\t\t\tif j == 0:\n",
        "\t\t\t\t\tCoeff[j] -= (Summation[j] / BatchSize) * LearningRate\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tCoeff[j] = (1 - LearningRate * LambdaParameter / m) * Coeff[j] - (Summation[j] / BatchSize) * LearningRate\n",
        "print(\"Final coefficients are:\")\n",
        "print(Coeff)\n",
        "\n",
        "# Finding Mean absolute percentage error.\n",
        "Error = 0\n",
        "for i in range(len(FeaturesTest)):\n",
        "\tpredicted = 0\n",
        "\tfor j in range(len(Coeff)):\n",
        "\t  \tpredicted = predicted + Coeff[j] * FeaturesTest[i][j]\n",
        "\tError += abs(predicted - PriceTest[i]) / PriceTest[i]\n",
        "Error = (Error / len(FeaturesTest)) * 100\n",
        "print(\"Mean absolute percentage error is : \" + str(Error))\n",
        "print()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using scaled batch gradient without regularisation\n",
            "Initial coefficients: \n",
            "[0, 0, 0, 0]\n",
            "Final coefficients are:\n",
            "[7730.872053867435, 8069.264303687423, 11077.015405893277, 18485.569122447192]\n",
            "Mean absolute percentage error is : 18.30641888247704\n",
            "\n",
            "Using scaled batch gradient with regularisation\n",
            "Initial coefficients: \n",
            "[0, 0, 0, 0]\n",
            "Final coefficients are:\n",
            "[5037.585668619078, 11147.667574879839, 10378.580439168689, 22647.298983883848]\n",
            "Mean absolute percentage error is : 19.92701396456417\n",
            "\n",
            "Using Stochastic gradient without regularisation\n",
            "Initial coefficients: \n",
            "[0, 0, 0, 0]\n",
            "Final coefficients are:\n",
            "[18648.663069990776, 15073.501985961251, 15766.862790309351, 22357.23427068568]\n",
            "Mean absolute percentage error is : 32.87903970192347\n",
            "\n",
            "Using Scaled Minibatch gradient without regularisation for batch size = 20\n",
            "Final coefficients are:\n",
            "[6340.552295015755, 2827.87646125345, 15916.90159915714, 10968.772912396124]\n",
            "Mean absolute percentage error is : 20.275262089497147\n",
            "\n",
            "Using Scaled Minibatch gradient with regularisation for batch size = 20\n",
            "Final coefficients are:\n",
            "[888.9201243627547, 5168.211726125255, 17701.360814619125, 15202.387873756412]\n",
            "Mean absolute percentage error is : 19.550681895981263\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-pyJUKd6ocn"
      },
      "source": [
        "#Question-6(d)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "def cal_err(Y_train, Y_pred):\n",
        "    error = 0\n",
        "    for i in range(len(Y_train)):\n",
        "        error += abs(Y_train[i] - Y_pred[i]) / Y_train[i]\n",
        "    error = error / len(Y_train)\n",
        "    return error * 100\n",
        "\n",
        "def kernel(X_train, xi, Tau):\n",
        "    return np.exp(-np.sum((xi - X_train) ** 2, axis = 1) / (2 * Tau * Tau))\n",
        "\n",
        "def LocallyWeightedLR(X_train, xi, Y_train, Tau):\n",
        "\tXT = np.transpose(X_train)\n",
        "\tW = kernel(X_train, xi, Tau)\n",
        "\tMXTW = XT * W\n",
        "\tMXTWX = np.matmul(MXTW, X_train)\n",
        "\tInverseMXTWX = np.linalg.pinv(MXTWX)\n",
        "\tInverseMXTWXMXTW = np.matmul(InverseMXTWX, MXTW)\n",
        "\tInverseMXTWXMXTWY = np.matmul(InverseMXTWXMXTW, Y_train)\n",
        "\tInverseMXTWXMXTWYTranspose = np.transpose(InverseMXTWXMXTWY)\n",
        "\treturn InverseMXTWXMXTWYTranspose.dot(xi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9IBpwN77YAO",
        "outputId": "3ee66ba2-e86d-4ee0-da10-ab97a226120a"
      },
      "source": [
        "input_data = pd.read_csv('https://raw.githubusercontent.com/ParthKataria/OperatingSystem/master/Housing%20Price%20data%20set.csv', usecols = [\"price\", \"lotsize\", \"bedrooms\", \"bathrms\"])\n",
        "FloorArea = input_data['lotsize']\n",
        "NoOfBedrooms = input_data['bedrooms']\n",
        "NoOfBathrooms = input_data['bathrms']\n",
        "Y_train = input_data['price']\n",
        "Y_train = np.array(Y_train)\n",
        "Y_train = Y_train.reshape(Y_train.shape[0], 1)\n",
        "\n",
        "# Performing feature scanning on FloorArea\n",
        "FloorArea_Mean = np.mean(FloorArea)\n",
        "FloorArea_Max = max(FloorArea)\n",
        "FloorArea_Min = min(FloorArea)\n",
        "FloorArea_Scaled = []\n",
        "for i in FloorArea:\n",
        "\tFloorArea_Scaled.append((i - FloorArea_Mean) / (FloorArea_Max - FloorArea_Min))\n",
        "\n",
        "X_train = []\n",
        "for i in range(len(FloorArea)):\n",
        "\tX_train.append([1, FloorArea_Scaled[i], NoOfBedrooms[i], NoOfBathrooms[i]])\n",
        "X_train = np.array(X_train)\n",
        "\n",
        "Tau = 0.00005\n",
        "print(\"Using Locally Weighted Linear Regression for Tau = \" + str(Tau))\n",
        "pred = []\n",
        "for i in range(X_train.shape[0]):\n",
        "\ty_pred = LocallyWeightedLR(X_train, X_train[i], Y_train, Tau)\n",
        "\tpred.append(y_pred)\n",
        "print(\"Mean absolute percentage error is : \" + str(cal_err(Y_train,pred)))\n",
        "print()\n",
        "\n",
        "Price = input_data['price']\n",
        "\n",
        "#segmenting the features\n",
        "FeaturesTrain = []\n",
        "for i in range(383):\n",
        "\tFeaturesTrain.append([1, FloorArea_Scaled[i], NoOfBedrooms[i], NoOfBathrooms[i]])\n",
        "PriceTrain = Price[:383]\n",
        "PriceTest = []\n",
        "FeaturesTest = []\n",
        "for i in range(383, len(Price)):\n",
        "\tFeaturesTest.append([1, FloorArea_Scaled[i], NoOfBedrooms[i], NoOfBathrooms[i]])\n",
        "\tPriceTest.append(Price[i])\n",
        "m = len(FeaturesTrain)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Locally Weighted Linear Regression for Tau = 5e-05\n",
            "Mean absolute percentage error is : [5.40732082]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_KOEh2Z8Dw3",
        "outputId": "08208e1d-bf47-4920-e14f-5d4e4f62b12a"
      },
      "source": [
        "# Function to calculate Slope to find coefficients\n",
        "def Slope(Coeff, FeaturesTrain, PriceTrain, ind):\n",
        "\tError = 0\n",
        "\tfor i in range(len(FeaturesTrain)):\n",
        "\t\titr = 0\n",
        "\t\tfor j in range(len(Coeff)):\n",
        "\t\t\titr = itr + Coeff[j] * FeaturesTrain[i][j]\n",
        "\t\tError += (itr - PriceTrain[i]) * FeaturesTrain[i][ind]\n",
        "\treturn Error\n",
        "\n",
        "# Using scaled batch gradient with regularisation\n",
        "print(\"Using scaled batch gradient with regularisation\")\n",
        "LearningRate = 0.001\n",
        "LambdaParameter = -49\n",
        "Coeff = [0, 0, 0, 0]\n",
        "print(\"Initial coefficients: \")\n",
        "print(Coeff)\n",
        "for epochs in range(5000):\n",
        "\tTempCoeff = Coeff.copy()\n",
        "\tfor j in range(len(Coeff)):\n",
        "\t\tif (j == 0):\n",
        "\t\t\tTempCoeff[j] = TempCoeff[j] - ((LearningRate / m) * (Slope(Coeff, FeaturesTrain, PriceTrain, j)))\t\n",
        "\t\telse:\n",
        "\t\t\tTempCoeff[j] = (1 - LearningRate * LambdaParameter / m) * TempCoeff[j] - ((LearningRate / m) * (Slope(Coeff, FeaturesTrain, PriceTrain, j)))\n",
        "\tCoeff = TempCoeff.copy()\n",
        "print(\"Final coefficients are:\")\n",
        "print(Coeff)\n",
        "\n",
        "# Finding Mean absolute percentage error.\n",
        "Error = 0\n",
        "for i in range(len(FeaturesTest)):\n",
        "\tpredicted = 0\n",
        "\tfor j in range(len(Coeff)):\n",
        "\t  \tpredicted = predicted + Coeff[j] * FeaturesTest[i][j]\n",
        "\tError += abs(predicted - PriceTest[i]) / PriceTest[i]\n",
        "Error = (Error / len(FeaturesTest)) * 100\n",
        "print(\"Mean absolute percentage error is : \" + str(Error))\n",
        "print()\n",
        "\n",
        "def SlopeStoch(Coeff,FeaturesTrain,ActualVal,ind):\n",
        "\titr = 0\n",
        "\tfor j in range(len(Coeff)):\n",
        "\t\titr = itr + Coeff[j]*FeaturesTrain[j]\n",
        "\treturn (itr - ActualVal) * FeaturesTrain[ind]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using scaled batch gradient with regularisation\n",
            "Initial coefficients: \n",
            "[0, 0, 0, 0]\n",
            "Final coefficients are:\n",
            "[5037.585668619078, 11147.667574879839, 10378.580439168689, 22647.298983883848]\n",
            "Mean absolute percentage error is : 19.92701396456417\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-ulSNZt8QP7",
        "outputId": "d27f56c3-aa7d-4a84-8a1a-5b3dbed681be"
      },
      "source": [
        "# Using Scaled Stochastic gradient with regularisation.\n",
        "print(\"Using Stochastic gradient with regularisation\")\n",
        "\n",
        "# I tried with different values of tau but found this to be the best.\n",
        "LearningRate = 0.001\n",
        "LambdaParameter = 142000\n",
        "Coeff = [0, 0, 0, 0]\n",
        "print(\"Initial coefficients: \")\n",
        "print(Coeff)\n",
        "\n",
        "for iter in range(10):\n",
        "\tfor i in range(len(PriceTrain)):\n",
        "\t\tTempCoeff = Coeff.copy()\n",
        "\t\tfor j in range(4):\n",
        "\t\t\tif j == 0:\n",
        "\t\t\t\tTempCoeff[j] = TempCoeff[j] - (LearningRate * (SlopeStoch(Coeff, FeaturesTrain[i], PriceTrain[i], j)))\n",
        "\t\t\telse:\n",
        "\t\t\t\tTempCoeff[j] = (1 - LearningRate * LambdaParameter / m) * TempCoeff[j] - (LearningRate * (SlopeStoch(Coeff, FeaturesTrain[i], PriceTrain[i], j)))\n",
        "\t\tCoeff = TempCoeff.copy()\n",
        "\n",
        "print(\"Final coefficients are:\")\n",
        "print(Coeff)\n",
        "\n",
        "# Finding Mean absolute percentage error.\n",
        "Error = 0\n",
        "for i in range(len(FeaturesTest)):\n",
        "\tpredicted = 0\n",
        "\tfor j in range(len(Coeff)):\n",
        "\t  \tpredicted = predicted + Coeff[j] * FeaturesTest[i][j]\n",
        "\tError += abs(predicted - PriceTest[i]) / PriceTest[i]\n",
        "Error = (Error / len(FeaturesTest)) * 100\n",
        "print(\"Mean absolute percentage error is : \" + str(Error))\n",
        "print()\n",
        "\n",
        "# Using Scaled Minibatch gradient with regularisation for batch size = 30\n",
        "print(\"Using Scaled Minibatch gradient with regularisation for batch size = 30\")\n",
        "\n",
        "BatchSize = 30;\n",
        "LearningRate = 0.002\n",
        "LambdaParameter = -372\n",
        "Coeff = [0, 0, 0, 0]\n",
        "NoOfBatches = math.ceil(len(PriceTrain) / BatchSize)\n",
        "equallyDiv = False\n",
        "if (len(PriceTrain) % BatchSize == 0):\n",
        "\tequallyDiv = True;\n",
        "\n",
        "for epoch in range(30):\n",
        "\tfor batch in range(NoOfBatches):\n",
        "\t\tSummation = [0, 0, 0, 0]\n",
        "\t\tfor j in range(len(Coeff)):\n",
        "\t\t\tfor i in range(BatchSize):\n",
        "\t\t\t\tif (batch * BatchSize + i == len(FeaturesTrain)):\n",
        "\t\t\t\t\tbreak\n",
        "\t\t\t\tPredictedValue = 0.0\n",
        "\t\t\t\tfor wj in range(len(Coeff)):\n",
        "\t\t\t\t\tPredictedValue += Coeff[wj] * FeaturesTrain[batch * BatchSize + i][wj]\n",
        "\t\t\t\tPredictedValue -= PriceTrain[batch * BatchSize + i]\n",
        "\t\t\t\tPredictedValue *= FeaturesTrain[batch * BatchSize + i][j]\n",
        "\t\t\t\tSummation[j] += PredictedValue;\n",
        "\n",
        "\t\tif (not equallyDiv and batch == NoOfBatches - 1):\n",
        "\t\t\tfor j in range(len(Summation)):\n",
        "\t\t\t\tif j == 0:\n",
        "\t\t\t\t\tCoeff[j] -= (Summation[j] / (len(PriceTrain) % BatchSize)) * LearningRate\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tCoeff[j] = (1 - LearningRate * LambdaParameter / m) * Coeff[j] - (Summation[j] / (len(PriceTrain) % BatchSize)) * LearningRate\n",
        "\t\telse:\n",
        "\t\t\tfor j in range(len(Summation)):\n",
        "\t\t\t\tif j == 0:\n",
        "\t\t\t\t\tCoeff[j] -= (Summation[j] / BatchSize) * LearningRate\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tCoeff[j] = (1 - LearningRate * LambdaParameter / m) * Coeff[j] - (Summation[j] / BatchSize) * LearningRate\n",
        "print(\"Final coefficients are:\")\n",
        "print(Coeff)\n",
        "\n",
        "# Finding Mean absolute percentage error.\n",
        "Error = 0\n",
        "for i in range(len(FeaturesTest)):\n",
        "\tpredicted = 0\n",
        "\tfor j in range(len(Coeff)):\n",
        "\t  \tpredicted = predicted + Coeff[j] * FeaturesTest[i][j]\n",
        "\tError += abs(predicted - PriceTest[i]) / PriceTest[i]\n",
        "Error = (Error / len(FeaturesTest)) * 100\n",
        "print(\"Mean absolute percentage error is : \" + str(Error))\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Stochastic gradient with regularisation\n",
            "Initial coefficients: \n",
            "[0, 0, 0, 0]\n",
            "Final coefficients are:\n",
            "[63592.672255517704, 50.82794652908167, 490.4664942089522, 198.33597517414273]\n",
            "Mean absolute percentage error is : 22.669921716639656\n",
            "\n",
            "Using Scaled Minibatch gradient with regularisation for batch size = 30\n",
            "Final coefficients are:\n",
            "[2681.43806108953, 2059.662947401348, 17584.987500198524, 12538.251896070407]\n",
            "Mean absolute percentage error is : 20.000670512331244\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgOOh5v78jLG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}